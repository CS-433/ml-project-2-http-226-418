{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-9_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-24_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-16_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-7_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-2_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-1_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-14_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-12_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-20_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-3_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-17_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-22_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-25_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-6_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-18_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-13_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-11_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-15_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-5_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-8_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-21_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-10_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-23_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-4_4d.npz\n",
      "loading extracted_data_convnext_10/convnext_small_imagenet_full_seed-0-19_4d.npz\n",
      "{'features.4.0': 50.38182217432129, 'features.5.17.block.0': 159.40542510778835, 'features.5.2.block.0': 41.766389085756806, 'features.5.9.block.0': 87.70991792220683}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'extracted_data_convnext_10/ed/new-ed.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew-ed.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(effective_dimensionality)\n\u001b[0;32m---> 54\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meffective_dimensionality\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myvenv3/lib/python3.11/site-packages/numpy/lib/npyio.py:639\u001b[0m, in \u001b[0;36msavez\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_dispatcher)\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    557\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save several arrays into a single file in uncompressed ``.npz`` format.\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    Provide arrays as keyword arguments to store them under the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \n\u001b[1;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myvenv3/lib/python3.11/site-packages/numpy/lib/npyio.py:736\u001b[0m, in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     compression \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZIP_STORED\n\u001b[0;32m--> 736\u001b[0m zipf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    739\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/myvenv3/lib/python3.11/site-packages/numpy/lib/npyio.py:103\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m    102\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowZip64\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/myvenv3/lib/python3.11/zipfile.py:1295\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(file, filemode)\n\u001b[1;32m   1296\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'extracted_data_convnext_10/ed/new-ed.npz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_convnext_10'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-23_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-22_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-16_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-5_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-12_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-20_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-25_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-18_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-4_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-21_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-3_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-1_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-11_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-13_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-9_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-6_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-17_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-7_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-19_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-24_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-14_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-2_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-10_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-15_4d.npz\n",
      "loading extracted_data_convnext_40/convnext_small_imagenet_100_seed-0-8_4d.npz\n",
      "{'features.4.0': 28.904303932374685, 'features.5.17.block.0': 107.17741220382737, 'features.5.2.block.0': 38.01176199399299, 'features.5.9.block.0': 69.49061810259244}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_convnext_40'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-22_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-8_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-1_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-21_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-11_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-17_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-6_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-24_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-15_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-4_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-5_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-12_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-20_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-13_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-9_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-10_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-7_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-23_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-14_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-25_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-2_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-18_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-16_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-3_4d.npz\n",
      "loading extracted_data_convnext_66/convnext_small_imagenet_10_seed-0-19_4d.npz\n",
      "{'features.4.0': 5.050157102972094, 'features.5.17.block.0': 20.855715485713542, 'features.5.2.block.0': 16.27112640476428, 'features.5.9.block.0': 18.501102974286816}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_convnext_66'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_resnet_12/resnet152_imagenet_full-15_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-19_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-5_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-21_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-11_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-9_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-18_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-12_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-1_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-7_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-8_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-2_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-20_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-10_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-17_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-4_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-23_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-25_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-3_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-14_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-24_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-16_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-22_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-6_4d.npz\n",
      "loading extracted_data_resnet_12/resnet152_imagenet_full-13_4d.npz\n",
      "{'layer1.0.bn1': 5.13484979362579, 'layer3.0.bn3': 52.41344568334473, 'layer3.3.bn3': 46.79651407894524, 'layer3.34.bn3': 44.707980969656056}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_resnet_12'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_resnet_34/resnet101_ecoset_full-8_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-15_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-22_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-6_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-3_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-17_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-11_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-7_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-1_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-4_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-16_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-25_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-23_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-9_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-21_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-12_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-5_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-20_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-24_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-14_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-19_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-2_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-13_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-18_4d.npz\n",
      "loading extracted_data_resnet_34/resnet101_ecoset_full-10_4d.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_resnet_34'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-15_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-17_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-23_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-7_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-3_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-4_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-20_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-11_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-8_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-9_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-5_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-19_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-12_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-25_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-6_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-24_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-1_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-13_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-22_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-18_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-16_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-2_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-21_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-10_4d.npz\n",
      "loading extracted_data_resnet_39/resnet50_imagenet_100_seed-0-14_4d.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_resnet_39'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading extracted_data_resnext_13/resnext101_32x32d_wsl-5_4d.npz\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_resnext_13'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('4d.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def flatten(layer_output):\n",
    "    return layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "def global_avg_pooling(layer_output):\n",
    "    if len(layer_output.shape) != 4:\n",
    "        raise ValueError(f\"Input features must be a 4D array instead of {layer_output.shape}D\")\n",
    "    return layer_output.mean(axis=(2, 3))\n",
    "\n",
    "# Define the directory containing .npz files\n",
    "folder_path = 'extracted_data_resnext_2'\n",
    "output_path = f'{folder_path}/ed'\n",
    "\n",
    "# Initialize a dictionary to store the aggregated sums\n",
    "aggregated_sums_num = {}\n",
    "aggregated_sums_denom = {}\n",
    "file_count = 0\n",
    "\n",
    "use_global_avg_pooling = True\n",
    "use_flatten = False\n",
    "\n",
    "all_data = {}\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.npz'):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        print(f'loading {file_path}')\n",
    "        data = np.load(file_path)\n",
    "        for key in data.files:\n",
    "            if key not in all_data:\n",
    "                all_data[key] = []\n",
    "            array = data[key]\n",
    "            \n",
    "            if use_global_avg_pooling:\n",
    "                array = global_avg_pooling(array)\n",
    "            \n",
    "            if use_flatten:\n",
    "                array = flatten(array)\n",
    "            \n",
    "            all_data[key].append(array)\n",
    "\n",
    "# Concatenate all arrays for each key\n",
    "for key in all_data:\n",
    "    all_data[key] = np.vstack(all_data[key])\n",
    "\n",
    "effective_dimensionality = {}\n",
    "for key, array in all_data.items():\n",
    "    singular_values = np.linalg.svd(array, compute_uv=False)\n",
    "    effective_dimensionality[key] = (singular_values.sum())**2 / (np.sum(singular_values**2))\n",
    "\n",
    "output_file = os.path.join(output_path, 'new-ed.npz')\n",
    "print(effective_dimensionality)\n",
    "np.savez(output_file, **effective_dimensionality)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
