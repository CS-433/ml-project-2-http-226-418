{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'project2 (Python 3.11.11)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/remmal/.pyenv/versions/3.11.11/envs/project2/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from brainscore_vision import load_model, load_stimulus_set\n",
    "model = load_model('alexnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model = model.activations_model\n",
    "act_model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in act_model.layers():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case this is how to access the baseline model\n",
    "model_ = act_model._model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_list = ['features.0', 'features.3', 'features.6', 'features.8', 'features.10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_model._model.features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = load_stimulus_set('FreemanZiemba2013.aperture-public')  # load some images for the model to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = model.activations_model._extractor.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extraction = act_model(stimuli, conv_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conv_layer_configs(xarray_data):\n",
    "    conv_layer_configs = {}\n",
    "    \n",
    "    # Extract unique layers\n",
    "    unique_layers = np.unique(xarray_data['layer'].values)\n",
    "    \n",
    "    for layer in unique_layers:\n",
    "        # Select data for the specific layer\n",
    "        layer_data = xarray_data.sel(neuroid=xarray_data['layer'] == layer)\n",
    "        \n",
    "        # Compute channels, height, and width\n",
    "        channels = len(np.unique(layer_data['channel'].values))\n",
    "        height = len(np.unique(layer_data['channel_y'].values))\n",
    "        width = len(np.unique(layer_data['channel_x'].values))\n",
    "        \n",
    "        # Add to config dictionary\n",
    "        conv_layer_configs[layer] = {\n",
    "            'channels': channels,\n",
    "            'height': height,\n",
    "            'width': width\n",
    "        }\n",
    "    \n",
    "    return conv_layer_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_configs = generate_conv_layer_configs(model_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_layer_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reshape_xarray_to_4d(xarray_data, conv_layer_configs):\n",
    "    reshaped_data = {}\n",
    "\n",
    "    # Extract metadata\n",
    "    presentation_size = len(xarray_data.presentation)\n",
    "\n",
    "    for layer, config in conv_layer_configs.items():\n",
    "        # Filter neuroids corresponding to the current layer\n",
    "        layer_data = xarray_data.sel(neuroid=xarray_data['layer'] == layer)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        expected_neuroids = config['channels'] * config['height'] * config['width']\n",
    "        if len(layer_data.neuroid) != expected_neuroids:\n",
    "            raise ValueError(\n",
    "                f\"Layer {layer} expects {expected_neuroids} neuroids, but got {len(layer_data.neuroid)}.\"\n",
    "            )\n",
    "\n",
    "        # Reshape to (batch_size, channels, height, width)\n",
    "        reshaped_layer = layer_data.values.reshape(\n",
    "            presentation_size, config['channels'], config['height'], config['width']\n",
    "        )\n",
    "        reshaped_data[layer] = reshaped_layer\n",
    "\n",
    "    return reshaped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_4d = reshape_xarray_to_4d(model_extraction, conv_layer_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to make flatten version (2D)\n",
    "\n",
    "# Get the list of layers\n",
    "layers = model_extraction['layer'].values\n",
    "\n",
    "# Extract features by layer\n",
    "features_by_layer = {layer: model_extraction.sel(neuroid=model_extraction['layer'] == layer).data for layer in conv_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to save in .npz format\n",
    "npz_data = {layer_name: features for layer_name, features in reshaped_4d.items()}\n",
    "\n",
    "# Save as an npz file\n",
    "np.savez('{}.npz'.format(model.identifier), **npz_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the npz file\n",
    "data = np.load('alexnet.npz')\n",
    "\n",
    "# Access data of a specific layer\n",
    "features_0 = data['features.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from sklearn.decomposition import PCA\n",
    "\n",
    "class EigenSpectraCalculator:\n",
    "    def __init__(self, layer_features):\n",
    "        \"\"\"\n",
    "        layer_features: Dictionary containing {layer_name: feature_list}\n",
    "        feature_list: A 2D numpy array of shape (num_samples, feature_dim)\n",
    "        \"\"\"\n",
    "        self.layer_features = layer_features\n",
    "        self._layer_eigenspectra = {}\n",
    "\n",
    "    def flatten(self, layer_output):\n",
    "      flattened = layer_output.reshape(layer_output.shape[0], -1)\n",
    "\n",
    "      return flattened\n",
    "\n",
    "    def global_avg_pooling(self, layer_output):\n",
    "      if len(layer_output.shape) != 4:\n",
    "        raise ValueError(\"Input features must be a 4-dim with shape (B, C, H, W).\")\n",
    "    \n",
    "      # Compute the global average pooling over the last two dimensions (H, W)\n",
    "      pooled_features = layer_output.mean(axis=(2, 3))\n",
    "      print(pooled_features.shape)\n",
    "      \n",
    "      return pooled_features\n",
    "\n",
    "    def compute_eigenspectra(self, use_global_avg_pooling=False):\n",
    "      \"\"\"\n",
    "      Compute eigenspectra for each layer based on the feature data using SVD.\n",
    "      \"\"\"\n",
    "      self._layer_eigenspectra = {}\n",
    "      for layer, features in self.layer_features.items():\n",
    "          # global average pooling\n",
    "          if use_global_avg_pooling:\n",
    "            features = self.global_avg_pooling(features)\n",
    "          else:\n",
    "            features = self.flatten(features)\n",
    "\n",
    "          print(features.shape)\n",
    "\n",
    "          # pca = PCA()\n",
    "          # pca.fit(features)\n",
    "\n",
    "          # eigenspectrum = pca.explained_variance_\n",
    "\n",
    "          # Center the features\n",
    "          centered_features = features - np.mean(features, axis=0)\n",
    "\n",
    "          # Compute the SVD\n",
    "          S = np.linalg.svd(centered_features, compute_uv=False)\n",
    "\n",
    "          eigenspectrum = (S ** 2) / (centered_features.shape[0] - 1)\n",
    "\n",
    "          #Store the eigenvalues as eigenspectra for the layer\n",
    "          self._layer_eigenspectra[layer] = eigenspectrum\n",
    "\n",
    "    def effective_dimensionalities(self):\n",
    "        \"\"\"\n",
    "        Calculate effective dimensionalities for each layer.\n",
    "        Effective Dimensionality = (Sum of eigenvalues)^2 / Sum of squared eigenvalues\n",
    "        \"\"\"\n",
    "        effdims = {\n",
    "            layer: eigspec.sum() ** 2 / (eigspec**2).sum()\n",
    "            for layer, eigspec in self._layer_eigenspectra.items()\n",
    "        }\n",
    "        return effdims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator_avg = EigenSpectraCalculator(reshaped_4d)\n",
    "calculator_avg.compute_eigenspectra(use_global_avg_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator_avg.effective_dimensionalities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator = EigenSpectraCalculator(reshaped_4d)\n",
    "calculator.compute_eigenspectra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator.effective_dimensionalities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = load_model('resnext101_32x48d_wsl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet1 = load_model('convnext_tiny_imagenet_full_seed-0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet1.activations_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in convnet1.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = load_model('resnet152_imagenet_full')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS-433",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
