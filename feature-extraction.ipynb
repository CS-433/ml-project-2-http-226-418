{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd41f734-0d56-460a-8103-23d799676ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from brainscore_vision import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58b4fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  'alexnet': ['features.2', 'features.7', 'features.7', 'features.12'],\n",
    "  'deit_base_imagenet_full_seed-0': ['blocks.3.mlp.fc1', 'blocks.8.norm2', 'blocks.3.mlp.act', 'blocks.9.norm2'],\n",
    "  'resnet-50-robust': ['layer3.0.downsample.0', 'layer4.0.downsample.0', 'layer3.0.downsample.0', 'layer4.0.downsample.0'],\n",
    "  'deit_large_imagenet_full_seed-0': ['blocks.4.norm1', 'blocks.18.norm2', 'blocks.9.norm1', 'blocks.20.norm2'],\n",
    "  'resnet152_imagenet_full': ['layer1.0.bn1', 'layer3.3.bn3', 'layer3.0.bn3', 'layer3.34.bn3'],\n",
    "  'resnext101_32x32d_wsl': ['layer1.0.relu', 'layer3.0.relu', 'layer2.0.relu', 'layer3.21.relu'],\n",
    "  'convnext_small_imagenet_100_seed-0': ['features.5.2.block.0', 'features.5.17.block.0', 'features.4.0', 'features.5.9.block.0'],\n",
    "  'convnext_small_imagenet_10_seed-0': ['features.5.2.block.0', 'features.5.17.block.0', 'features.4.0', 'features.5.9.block.0'],\n",
    "  'resnext101_32x48d_wsl': ['layer2.2.relu', 'layer3.0.relu', 'layer2.0.relu', 'layer3.20.relu'],\n",
    "  'resnet50_ecoset_full': ['layer1.0.bn1', 'layer4.0.conv2', 'layer3.0.conv1', 'layer4.0.relu'],\n",
    "  'resnet50_imagenet_100_seed-0': ['layer1.0.conv1', 'layer3.5.bn3', 'layer3.0.conv1', 'layer4.0.relu'],\n",
    "  'resnet101_ecoset_full': ['layer1.0.bn1', 'layer3.4.relu', 'layer3.0.bn3', 'layer4.0.relu'],\n",
    "  'resnext101_32x8d_wsl': ['layer2.3.relu', 'layer3.4.relu', 'layer2.1.relu', 'layer3.3.relu'],\n",
    "  'convnext_small_imagenet_full_seed-0': ['features.5.2.block.0', 'features.5.17.block.0', 'features.4.0', 'features.5.9.block.0'],\n",
    "  'convnext_tiny_imagenet_full_seed-0': ['features.6.0', 'features.5.4.block.0', 'features.4.0', 'features.5.4.block.0'],\n",
    "  'deit_small_imagenet_100_seed-0': ['blocks.2.norm1', 'blocks.6.norm2', 'blocks.5.norm1', 'blocks.9.norm2'],\n",
    "  'convnext_base_imagenet_full_seed-0': ['features.5.7.block.0', 'features.5.12.block.0', 'features.4.0', 'features.5.11.block.0'],\n",
    "  'resnet50_tutorial': ['layer2', 'layer2', 'layer2', 'layer3'],\n",
    "  'resnet101_imagenet_full': ['layer1.0.bn1', 'layer4.0.bn1', 'layer3.0.bn3', 'layer4.0.relu'],\n",
    "  'convnext_large_imagenet_full_seed-0': ['features.5.7.block.5', 'features.5.7.block.0', 'features.4.1', 'features.5.11.block.0'],\n",
    "  'resnet50_imagenet_full': ['layer1.0.conv1', 'layer3.5.bn3', 'layer3.0.conv1', 'layer4.0.relu'],\n",
    "  'resnet18_imagenet_full': ['layer1.0.bn1', 'layer3.0.conv2', 'layer2.0.bn2', 'layer4.0.bn1'],\n",
    "  'resnet152_ecoset_full': ['layer1.0.bn1', 'layer3.3.bn3', 'layer3.0.bn3', 'layer4.0.relu'],\n",
    "  'resnet18_ecoset_full': ['layer1.0.conv1', 'layer3.0.conv1', 'layer2.0.bn2', 'layer4.0.bn1'],\n",
    "  'resnet-152_v2_pytorch': ['avgpool', 'layer4.1.relu', 'layer4.1.relu', 'layer4.1.bn2'],\n",
    "  'resnet34_ecoset_full': ['layer1.0.bn1', 'layer3.1.conv1', 'layer3.0.conv1', 'layer4.0.conv1'],\n",
    "  'resnet18_imagenet21kP': ['layer2.0.relu', 'layer2.0.relu', 'layer2.0.relu', 'layer4.0.relu'],\n",
    "  'deit_small_imagenet_full_seed-0': ['blocks.2.norm1', 'blocks.6.norm2', 'blocks.5.norm1', 'blocks.9.norm2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45464eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet = f'{ os.getcwd() }/data/imagenet/val'\n",
    "stimuli = glob.glob(os.path.join(imagenet, '**'), recursive=True)\n",
    "stimuli = [ stimulus for stimulus in stimuli if os.path.isfile(stimulus) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e88399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = f'{ os.getcwd() }/data/output/deit-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7a5fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(model, layers, batch_size = 2000):\n",
    "  model = load_model(model)\n",
    "  act_model = model.activations_model\n",
    "  output = f'{ os.getcwd() }/data/output/{model.identifier}'\n",
    "  counter = 1\n",
    "  for batch_start in range(0, len(stimuli), batch_size):\n",
    "    # Get the current batch of stimuli\n",
    "    batch = stimuli[batch_start:batch_start + batch_size]\n",
    "    print(f'{counter} - running the model ({batch_start})...')\n",
    "    # Extract model activations for the batch\n",
    "    model_extraction = act_model(batch, layers)\n",
    "    print('building the npz...')\n",
    "    npz_data = {\n",
    "        layer: model_extraction.sel(neuroid=model_extraction['layer'] == layer).data\n",
    "        for layer in layers\n",
    "      }\n",
    "    print('persisting the data...')\n",
    "    np.savez(os.path.join(output, '{}-{}.npz'.format(model.identifier, counter)), **npz_data)\n",
    "\n",
    "    # Increment the counter\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10279a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, layers in models.items():\n",
    "    extract(model, layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs433-project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
