{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center>Reshape the Data to 4D matrices</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the directory containing the files\n",
    "output_dir = f'{ os.getcwd() }/data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "  'alexnet': {\n",
    "      'features.2': (64, 27, 27), \n",
    "      'features.7': (384, 13, 13),\n",
    "      'features.7': (384, 13, 13), \n",
    "      'features.12': (256, 6, 6)\n",
    "      },\n",
    "  'resnet-50-robust': {\n",
    "      'layer3.0.downsample.0': (1024, 14, 14), \n",
    "      'layer4.0.downsample.0': (2048, 7, 7), \n",
    "      'layer3.0.downsample.0': (1024, 14, 14), \n",
    "      'layer4.0.downsample.0': (2048, 7, 7)\n",
    "      },\n",
    "  'resnet152_imagenet_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer3.3.bn3': (1024, 14, 14), \n",
    "      'layer3.0.bn3': (1024, 14, 14), \n",
    "      'layer3.34.bn3': (1024, 14, 14)\n",
    "    },\n",
    "  'resnext101_32x32d_wsl': {\n",
    "      'layer1.0.relu': (256, 56, 56), \n",
    "      'layer3.0.relu': (1024, 14, 14), \n",
    "      'layer2.0.relu': (512, 28, 28), \n",
    "      'layer3.21.relu': (1024, 14, 14)\n",
    "    },\n",
    "  'convnext_small_imagenet_100_seed-0': {\n",
    "      'features.5.2.block.0': (384, 14, 14), \n",
    "      'features.5.17.block.0': (384, 14, 14), \n",
    "      'features.4.0': (192, 28, 28), \n",
    "      'features.5.9.block.0': (384, 14, 14)\n",
    "    },\n",
    "  'convnext_small_imagenet_10_seed-0': {\n",
    "      'features.5.2.block.0': (384, 14, 14), \n",
    "      'features.5.17.block.0': (384, 14, 14), \n",
    "      'features.4.0': (192, 28, 28), \n",
    "      'features.5.9.block.0': (384, 14, 14)\n",
    "    },\n",
    "  'resnext101_32x48d_wsl': {\n",
    "      'layer2.2.relu': (512, 28, 28), \n",
    "      'layer3.0.relu': (1024, 14, 14), \n",
    "      'layer2.0.relu': (512, 28, 28), \n",
    "      'layer3.20.relu': (1024, 14, 14)\n",
    "      },\n",
    "  'resnet50_ecoset_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer4.0.conv2': (512, 7, 7), \n",
    "      'layer3.0.conv1': (256, 28, 28), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "    },\n",
    "  'resnet50_imagenet_100_seed-0': {\n",
    "      'layer1.0.conv1': (64, 56, 56), \n",
    "      'layer3.5.bn3': (1024, 14, 14), \n",
    "      'layer3.0.conv1': (256, 28, 28), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "    },\n",
    "  'resnet101_ecoset_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer3.4.relu': (1024, 14, 14), \n",
    "      'layer3.0.bn3': (1024, 14, 14), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "      },\n",
    "  'resnext101_32x8d_wsl': {\n",
    "      'layer2.3.relu': (512, 28, 28), \n",
    "      'layer3.4.relu': (1024, 14, 14), \n",
    "      'layer2.1.relu': (512, 28, 28), \n",
    "      'layer3.3.relu': (1024, 14, 14)\n",
    "      },\n",
    "  'convnext_small_imagenet_full_seed-0': {\n",
    "      'features.5.2.block.0': (384, 14, 14), \n",
    "      'features.5.17.block.0': (384, 14, 14), \n",
    "      'features.4.0': (192, 28, 28), \n",
    "      'features.5.9.block.0': (384, 14, 14)\n",
    "      },\n",
    "  'convnext_tiny_imagenet_full_seed-0': {\n",
    "      'features.6.0': (384, 14, 14), \n",
    "      'features.5.4.block.0': (384, 14, 14), \n",
    "      'features.4.0': (192, 28, 28), \n",
    "    },\n",
    "  'convnext_base_imagenet_full_seed-0': {\n",
    "      'features.5.7.block.0': (512, 14, 14), \n",
    "      'features.5.12.block.0': (512, 14, 14), \n",
    "      'features.4.0': (256, 28, 28), \n",
    "      'features.5.11.block.0': (512, 14, 14)\n",
    "      },\n",
    "  'resnet50_tutorial': {\n",
    "      'layer2': (512, 28, 28), \n",
    "      'layer3': (1024, 14, 14)\n",
    "      },\n",
    "  'resnet101_imagenet_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer4.0.bn1': (512, 14, 14), \n",
    "      'layer3.0.bn3': (1024, 14, 14), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "      },\n",
    "  'convnext_large_imagenet_full_seed-0': {\n",
    "      'features.5.7.block.5': (14, 14, 768), \n",
    "      'features.5.7.block.0': (768, 14, 14), \n",
    "      'features.4.1': (768, 14, 14), \n",
    "      'features.5.11.block.0': (768, 14, 14)\n",
    "      },\n",
    "  'resnet50_imagenet_full': {\n",
    "      'layer1.0.conv1': (64, 56, 56), \n",
    "      'layer3.5.bn3': (1024, 14, 14), \n",
    "      'layer3.0.conv1': (256, 28, 28), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "      },\n",
    "  'resnet18_imagenet_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer3.0.conv2': (256, 14, 14), \n",
    "      'layer2.0.bn2': (128, 28, 28), \n",
    "      'layer4.0.bn1': (512, 7, 7)\n",
    "      },\n",
    "  'resnet152_ecoset_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer3.3.bn3': (1024, 14, 14), \n",
    "      'layer3.0.bn3': (1024, 14, 14), \n",
    "      'layer4.0.relu': (2048, 7, 7)\n",
    "      },\n",
    "  'resnet18_ecoset_full': {\n",
    "      'layer1.0.conv1': (64, 56, 56), \n",
    "      'layer3.0.conv1': (256, 14, 14), \n",
    "      'layer2.0.bn2': (128, 28, 28), \n",
    "      'layer4.0.bn1': (512, 7, 7)\n",
    "      },\n",
    "  'resnet-152_v2_pytorch': {\n",
    "      'avgpool': (2048, 1, 1), \n",
    "      'layer4.1.relu': (2048, 10, 10),\n",
    "      'layer4.1.bn2': (512, 10, 10)\n",
    "      },\n",
    "  'resnet34_ecoset_full': {\n",
    "      'layer1.0.bn1': (64, 56, 56), \n",
    "      'layer3.1.conv1': (256, 14, 14), \n",
    "      'layer3.0.conv1': (256, 14, 14), \n",
    "      'layer4.0.conv1': (512, 7, 7)\n",
    "      },\n",
    "  'resnet18_imagenet21kP': {\n",
    "      'layer2.0.relu': (128, 28, 28),\n",
    "      'layer4.0.relu': (512, 7, 7)\n",
    "      },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(key, shapes):\n",
    "  key_folder = os.path.join(output_dir, key)\n",
    "  for i in range(1, 26):\n",
    "    file_path = os.path.join(key_folder, f'key-{i}.npz')\n",
    "    if not os.path.exists(file_path):\n",
    "      print(f\"File {file_path} does not exist, skipping...\")\n",
    "      continue\n",
    "    print(f\"\\nProcessing file: {file_path}\")\n",
    "    data = np.load(file_path)\n",
    "    reshaped_data = {}\n",
    "    for layer_name in data.files:\n",
    "      print(f\"  Processing layer: {layer_name}\")\n",
    "      layer_data = data[layer_name]\n",
    "      batch_size, neuroids = layer_data.shape\n",
    "        \n",
    "      # Fetch the target shape for the current layer\n",
    "      if layer_name in shapes:\n",
    "        channels, height, width = shapes[layer_name]\n",
    "      else:\n",
    "        raise ValueError(f\"Shape for layer {layer_name} not defined.\")\n",
    "        \n",
    "      # Validate shape consistency\n",
    "      assert channels * height * width == neuroids, (\n",
    "        f\"Mismatch in reshaping dimensions for {layer_name}: \"\n",
    "        f\"Expected {channels * height * width}, got {neuroids}\"\n",
    "      )\n",
    "        \n",
    "      # Reshape to 4D tensor\n",
    "      reshaped = layer_data.reshape(batch_size, channels, height, width)\n",
    "      reshaped_data[layer_name] = reshaped\n",
    "        \n",
    "      print(f\"Reshaped {layer_name} to {reshaped.shape}\")\n",
    "    np.savez(file_path, **reshaped_data)\n",
    "    print(f\"Overwritten file with reshaped data: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, shapes in models.items():\n",
    "  reshape(key, shapes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs433-project2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
